Namespace(annpath='train.json', batch_size=1, bs=8, clip_len=64, cuda=True, dataparallel=True, emb_init='../wordvectors/glove.6B.300d.txt', embedding_size=512, feature_size=2048, framepath='frames', ft_begin_index=0, imsize=224, json_path=None, langmethod='Transformer', log_every=10, lr=0.0001, lstm_memory=512, lstm_pretrain_ep=0, lstm_stacks=1, manual_seed=1, max_epochs=1000, max_seqlen=30, meta_path='videometa_train.json', mode='train', model_ep=100, model_path='../models', modeldepth=101, modelname='resnext', momentum=0.9, n_classes=739, n_cpu=12, n_finetune_classes=739, norm_value=1, num_layers=18, patience=10, pretrain_path='../models/save_105.pth', resnet_shortcut='A', resnext_cardinality=32, root_path='/ssd1/dsets/activitynet_captions', start_from_ep=0, submission_path='submission.json', token_level=False, vocabpath='vocab_pad.json', weight_decay=0.0001, wide_resnet_k=2)
loaded dictionary from /ssd1/dsets/activitynet_captions/vocab_pad.json
dictionary length: 11182 words
loaded pretrain models from ../models/save_105.pth
using 4 gpus...
# of params in model : 98433984
start decoder pretraining, doing for 0 epochs
done with decoder pretraining
start training
duration of clip (24) does not match specified size
duration of clip (2) does not match specified size
duration of clip (9) does not match specified size
duration of clip (62) does not match specified size
duration of clip (45) does not match specified size
elapsed: 26s | iter 000010/001133 | nll loss: 9.5649 | 2.6960s per loop
duration of clip (42) does not match specified size
elapsed: 37s | iter 000020/001133 | nll loss: 8.9916 | 1.0856s per loop
duration of clip (63) does not match specified size
Traceback (most recent call last):
  File "train.py", line 205, in <module>
    for it, data in enumerate(trainloader):
  File "/home/seito/anaconda3/envs/anetchallenge/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 623, in __next__
    return self._process_next_batch(batch)
  File "/home/seito/anaconda3/envs/anetchallenge/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 658, in _process_next_batch
    raise batch.exc_type(batch.exc_msg)
UnboundLocalError: Traceback (most recent call last):
  File "../dataset/activitynet_captions.py", line 246, in __getitem__
    tmp = self.data[index]['segments']
KeyError: 'segments'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/seito/anaconda3/envs/anetchallenge/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/home/seito/anaconda3/envs/anetchallenge/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 138, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "../dataset/activitynet_captions.py", line 249, in __getitem__
    print("no key 'segments', id={}".format(id), flush=True)
UnboundLocalError: local variable 'id' referenced before assignment

